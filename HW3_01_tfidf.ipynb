{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from googletrans import Translator\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "#translator = Translator()\n",
    "from pathlib import Path\n",
    "import math\n",
    "'''\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "'''\n",
    "\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading tsvs and getting cleaned stemmed dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the given dataset into pandas for processing using only the needed columns\n",
    "data = pd.read_csv('Airbnb_Texas_Rentals.csv', nrows=10, usecols= ['average_rate_per_night', 'bedrooms_count','city', 'date_of_listing', 'description', 'latitude','longitude','title', 'url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file for every row in data(the given data of airbnb)\n",
    "fileCount = 0\n",
    "for index, r in data.iterrows():\n",
    "    data_temp = data.loc[index:index]\n",
    "    fileCount +=1\n",
    "    data_temp.to_csv('data/doc_'+str(index+1)+'.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the functions\n",
    "\n",
    "\n",
    "    # list of unique words (terms) to be used to build the vocabulary\n",
    "    words = []\n",
    "\n",
    "    def cleanData(rawData):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "        # TODO translatoin\n",
    "        #lang = detect(t4[0])\n",
    "        #print(lang)\n",
    "        #rawData = translator.translate(rawData, dest='en')\n",
    "\n",
    "        # get words lowercased\n",
    "        t0 = rawData.lower()\n",
    "        # remove puctuations\n",
    "        t1 = tokenizer.tokenize(t0)\n",
    "        #t2Data = stemmer.stem(i for i in t1Data)\n",
    "        #print(len(t1))\n",
    "        # reomve stop words\n",
    "        t2 =[]\n",
    "        t2 = [t1[i] for i in range(0,len(t1)) if t1[i] not in stop_words]\n",
    "\n",
    "        # stemm words\n",
    "        t3 = [stemmer.stem(t2[i]) for i in range(0, len(t2))]\n",
    "\n",
    "        # remove nummbers and strings starting with numbers\n",
    "        t4 = [t3[i] for i in range(0, len(t3)) if t3[i][0].isdigit()==False]\n",
    "\n",
    "\n",
    "        #print(t4)\n",
    "        return(t4)\n",
    "\n",
    "    def getWordsTSV(fid):\n",
    "        fileWords=[]\n",
    "        for i in open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\"):\n",
    "            #words.append(cleanData(i[0][4]))\n",
    "            data = [i.strip('\\n').split('\\t') for i in open('data/doc_'+str(fid)+'.tsv',encoding=\"utf8\")]\n",
    "            for w in (cleanData(data[0][4].replace('\\\\n', ' '))):\n",
    "                if w not in fileWords: fileWords.append(w)\n",
    "        return(fileWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*getWordsTSV(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcom', 'stay', 'privat', 'room', 'queen', 'bed', 'detach', 'bathroom', 'second', 'floor', 'anoth', 'bedroom', 'sofa', 'avail', 'addit', 'guest', 'iah', 'airport', 'pick', 'drop', 'trip', 'stylish', 'fulli', 'remodel', 'home', 'upscal', 'nw', 'alamo', 'height', 'area', 'amaz', 'locat', 'hous', 'conveni', 'quiet', 'street', 'beauti', 'season', 'tree', 'prestigi', 'neighborhood', 'close', 'loop', 'town', 'featur', 'open', 'plan', 'origin', 'hardwood', 'full', 'independ', 'garden', 'tv', 'sleep', 'european', 'inspir', 'kitchen', 'top', 'line', 'decor', 'driveway', 'park', 'car', 'river', 'island', 'citi', 'well', 'maintain', 'san', 'jacinto', 'extra', 'temporari', 'visitor', 'cute', 'littl', 'situat', 'covet', 'acr', 'bryan', 'access', 'recent', 'purchas', 'mile', 'outsid', 'downtown', 'fort', 'worth', 'happi', 'restor', 'charact', 'built', 'minut', 'drive', 'offer', 'across', 'current', 'rejuven', 'gateway', 'place', 'lake', 'conro', 'famili', 'friend', 'activ', 'nightlif', 'love', 'outdoor', 'space', 'good', 'coupl', 'solo', 'adventur', 'busi', 'travel', 'kid', 'big', 'group', 'rustic', 'countri', 'retreat', 'southeast', 'austin', 'convert', 'modular', 'amen', 'need', 'texa', 'experi', 'less', 'circuit', 'america', 'cota', 'formula', 'one', 'trailer', 'size', 'closet', 'pet', 'alway', 'clean', 'share', 'suppli', 'towel', 'shampoo', 'tcu', 'tcc', 'stockyard', 'first', 'class', 'comfort', 'condo', 'best', 'view', 'bottom', 'deck', 'master', 'patio', 'r', 'pier', 'step', 'away']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,fileCount):\n",
    "    t = getWordsTSV(i)\n",
    "    for w in t:\n",
    "        if w not in words:\n",
    "            words.append(w)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PS\n",
    "dunno why the stemmer is removing the last 'e' from any word\n",
    "we need to look at the stem function again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(*words)\n",
    "#words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reset the words \n",
    "#words =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the vocabulary file from the words \n",
    "wordsCount=0\n",
    "with open('vocabulary.csv','wb') as vfile:\n",
    "    for i in range(0,len(words)):\n",
    "        vfile.write(str(wordsCount).encode())\n",
    "        vfile.write(str('\\t').encode())\n",
    "        vfile.write(str(words[i]).encode())\n",
    "        vfile.write('\\n'.encode())\n",
    "        wordsCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 5], 1: [1], 2: [1, 4, 10], 3: [1, 2, 3], 4: [1, 8], 5: [1, 8], 6: [1], 7: [1, 2, 4, 8], 8: [1], 9: [1, 2], 10: [1], 11: [1, 2, 4, 8, 9], 12: [1], 13: [1, 7, 8], 14: [1], 15: [1], 16: [1], 17: [1, 2, 7], 18: [1], 19: [1], 20: [1], 21: [2], 22: [2], 23: [2], 24: [2, 4, 5, 7], 25: [2], 26: [2], 27: [2], 28: [2], 29: [2], 30: [2], 31: [2], 32: [2, 3, 8], 33: [2], 34: [2], 35: [2, 5], 36: [2, 8], 37: [2], 38: [2], 39: [2], 40: [2, 4, 6], 41: [2, 3, 6], 42: [2], 43: [2], 44: [2], 45: [2], 46: [2], 47: [2, 5], 48: [2], 49: [2], 50: [2], 51: [2, 4], 52: [2], 53: [2], 54: [2], 55: [2], 56: [2], 57: [2], 58: [2], 59: [2], 60: [2], 61: [2, 5, 7], 62: [2], 63: [3], 64: [3], 65: [3], 66: [3], 67: [3], 68: [3], 69: [3], 70: [3], 71: [3], 72: [3], 73: [4], 74: [4], 75: [4], 76: [4], 77: [4, 7], 78: [4], 79: [4], 80: [5], 81: [5], 82: [5, 7, 8], 83: [5], 84: [5, 8], 85: [5], 86: [5], 87: [5], 88: [5], 89: [5], 90: [5], 91: [5], 92: [5], 93: [5, 7], 94: [5], 95: [5], 96: [5], 97: [5], 98: [6], 99: [6], 100: [6], 101: [6], 102: [6], 103: [6], 104: [6], 105: [6], 106: [6], 107: [6], 108: [6], 109: [6], 110: [6], 111: [6], 112: [6], 113: [6], 114: [6], 115: [6], 116: [6], 117: [7], 118: [7], 119: [7], 120: [7], 121: [7], 122: [7], 123: [7], 124: [7], 125: [7], 126: [7], 127: [7], 128: [7], 129: [7], 130: [7], 131: [7], 132: [7], 133: [7], 134: [7], 135: [8], 136: [8], 137: [8], 138: [8], 139: [8], 140: [8], 141: [8], 142: [8], 143: [8], 144: [8], 145: [8], 146: [8], 147: [9], 148: [9], 149: [9], 150: [9], 151: [9], 152: [9], 153: [9], 154: [9], 155: [9], 156: [9], 157: [9], 158: [9], 159: [9], 160: [9]}\n"
     ]
    }
   ],
   "source": [
    "# creating index-file by loading vocabulary file and then comparing files with all vocabularys\n",
    "with open('vocabulary.csv', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    voc = list(map(tuple, reader))\n",
    "#print(voc)\n",
    "\n",
    "index = {}\n",
    "for i in range(len(voc)):\n",
    "    tempL=[]\n",
    "\n",
    "    for j in range(1,fileCount+1):\n",
    "        temp = getWordsTSV(j)\n",
    "        #print(temp)\n",
    "        if voc[i][1] in temp:\n",
    "            tempL.append(j)\n",
    "            \n",
    "        if len(tempL)!=0: index[i]= tempL\n",
    "            \n",
    "print(index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['德州农机大学', 'texa', 'amp', 'univers', '北门附近2b1b其中的一间卧室提供日租', '位置便利', '步行进入校区只需要5分钟', '室友为中国男生', '好相处', '日租时间段为2015年12月9日', '适合刚来学校没有车或者不打算买车的同学和老师', '男性']\n"
     ]
    }
   ],
   "source": [
    "#print(cleanData(\"德州农机大学(Texas A&amp;M University)北门附近2b1b其中的一间卧室提供日租。位置便利,步行进入校区只需要5分钟;室友为中国男生,好相处;日租时间段为2015年12月9日~30日。适合刚来学校没有车或者不打算买车的同学和老师(男性)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getID(term):\n",
    "    with open('vocabulary.csv', newline='') as voc:\n",
    "        line = csv.reader(voc, delimiter='\\t')\n",
    "        w = list(map(tuple, line))\n",
    "        #print(w[0][1])\n",
    "        for i in w:\n",
    "            if term == i[1]:\n",
    "                return (i[0])\n",
    "        else:\n",
    "            return None \n",
    "\n",
    "#getID('Hass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes term ID and returns the list of files containing the term\n",
    "def getDocsWithID(tid):\n",
    "    for k in index:\n",
    "        if tid == k:\n",
    "            return(index.get(k))\n",
    "    return None\n",
    "\n",
    "#getting error: TypeError: 'int' object is not iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDocsWithID(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed it to check if the doc contains all terms\n",
    "def getDocswithQuery(q):\n",
    "    ts = cleanData(q)\n",
    "    docsIDs = getDocsWithID(int(getID(ts[0])))\n",
    "    if len(ts) == 0 : return None\n",
    "    if len(ts)>1:\n",
    "        docsIDs = getDocsWithID(int(getID(ts[0])))\n",
    "        for t in ts:\n",
    "            if getID(t) != None:\n",
    "                tempDocs = getDocsWithID(int(getID(t)))\n",
    "                if tempDocs != None:\n",
    "                    docsIDs = set(docsIDs).intersection(tempDocs)\n",
    "            return None\n",
    "    return(list(docsIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-52c126065468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetDocsWithID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-b5af00b7c497>\u001b[0m in \u001b[0;36mgetDocsWithID\u001b[1;34m(tid)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# function takes term ID and returns the list of files containing the term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetDocsWithID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "getDocsWithID(int(getID('bed')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a2075468a56e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetDocswithQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bed private beautigul'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-d0730639e54b>\u001b[0m in \u001b[0;36mgetDocswithQuery\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetDocswithQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdocsIDs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDocsWithID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-b5af00b7c497>\u001b[0m in \u001b[0;36mgetDocsWithID\u001b[1;34m(tid)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# function takes term ID and returns the list of files containing the term\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetDocsWithID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "getDocswithQuery('bed private beautigul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetails(fid):\n",
    "    with open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\") as file:\n",
    "        line = csv.reader(file, delimiter='\\t')\n",
    "        cls = list(map(str, *line))\n",
    "        print(cls[7],cls[4], cls[2], cls[8])\n",
    "        # TODO create a table and list the details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetails(fid):\n",
    "    detlist =[]\n",
    "    with open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\") as file:\n",
    "        line = csv.reader(file, delimiter='\\t')\n",
    "        cls = list(map(str, *line))\n",
    "        detlist= [cls[7],cls[4], cls[2], cls[8]]\n",
    "        #TODO create a table and list the details\n",
    "        return detlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printResults(query):\n",
    "    docs = getDocswithQuery(query)\n",
    "    #det =[['Title','Description', 'City','Url']]\n",
    "    #for doc in docs:\n",
    "    #    det.append(getDetails(doc))\n",
    "    #columns = ('Title','Description', 'City','Url')\n",
    "    #n_rows = len(det)\n",
    "    html='<table align=\"left\"><tr><th>Title</th><th>Description</th><th>City</th><th>URL</th></tr>'\n",
    "    for doc in docs:\n",
    "        l = getDetails(doc)\n",
    "        html+='<tr><td>'+l[0]+'</td><td>'+l[1]+'</td><td>'+l[2]+'</td><td>'+l[3]+'</td></tr>'\n",
    "    html+='</table>'\n",
    "    display(HTML(html))\n",
    "    #table = ff.create_table(det, height_constant=60)\n",
    "    \n",
    "    #plotly.offline.iplot(table, filename='simple_table')\n",
    "    #plt.show()\n",
    "    #return det[0][1]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Private rooms/bathroom 10min from IAH airport Welcome to stay in private room with queen bed and detached private bathroom on the second floor. Another private bedroom with sofa bed is available for additional guests. 10$ for an additional guest.\\n10min from IAH airport\\nAirport pick-up/drop off is available for $10/trip. Humble https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-89893abe3b03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprintResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bed \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-9f2f0ad8c7a0>\u001b[0m in \u001b[0;36mprintResults\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mhtml\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m'<tr><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td></tr>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mhtml\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m'</table>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "printResults(\"Bed \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Private rooms/bathroom 10min from IAH airport Welcome to stay in private room with queen bed and detached private bathroom on the second floor. Another private bedroom with sofa bed is available for additional guests. 10$ for an additional guest.\\n10min from IAH airport\\nAirport pick-up/drop off is available for $10/trip. Humble https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-85485d4f93ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprintResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-9f2f0ad8c7a0>\u001b[0m in \u001b[0;36mprintResults\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDetails\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mhtml\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m'<tr><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td><td>'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'</td></tr>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mhtml\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;34m'</table>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "printResults(\"bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "print(getDocsWithID(160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(getDocswithQuery(\"a beautiful house with garden and beach\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData(\"Bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(getID('bed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from google.cloud import translate\n",
    "translate_client = translate.Client()\n",
    "text = u'Hello, world!'\n",
    "target = 'ru'\n",
    "# Translates some text into Russian\n",
    "translation = translate_client.translate(\n",
    "    text,\n",
    "    target_language=target)\n",
    "\n",
    "print(u'Text: {}'.format(text))\n",
    "print(u'Translation: {}'.format(translation['translatedText']))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1, 5], 1: [1], 2: [1, 4, 10], 3: [1, 2, 3], 4: [1, 8], 5: [1, 8], 6: [1], 7: [1, 2, 4, 8], 8: [1], 9: [1, 2], 10: [1], 11: [1, 2, 4, 8, 9], 12: [1], 13: [1, 7, 8], 14: [1], 15: [1], 16: [1], 17: [1, 2, 7], 18: [1], 19: [1], 20: [1], 21: [2], 22: [2], 23: [2], 24: [2, 4, 5, 7], 25: [2], 26: [2], 27: [2], 28: [2], 29: [2], 30: [2], 31: [2], 32: [2, 3, 8], 33: [2], 34: [2], 35: [2, 5], 36: [2, 8], 37: [2], 38: [2], 39: [2], 40: [2, 4, 6], 41: [2, 3, 6], 42: [2], 43: [2], 44: [2], 45: [2], 46: [2], 47: [2, 5], 48: [2], 49: [2], 50: [2], 51: [2, 4], 52: [2], 53: [2], 54: [2], 55: [2], 56: [2], 57: [2], 58: [2], 59: [2], 60: [2], 61: [2, 5, 7], 62: [2], 63: [3], 64: [3], 65: [3], 66: [3], 67: [3], 68: [3], 69: [3], 70: [3], 71: [3], 72: [3], 73: [4], 74: [4], 75: [4], 76: [4], 77: [4, 7], 78: [4], 79: [4], 80: [5], 81: [5], 82: [5, 7, 8], 83: [5], 84: [5, 8], 85: [5], 86: [5], 87: [5], 88: [5], 89: [5], 90: [5], 91: [5], 92: [5], 93: [5, 7], 94: [5], 95: [5], 96: [5], 97: [5], 98: [6], 99: [6], 100: [6], 101: [6], 102: [6], 103: [6], 104: [6], 105: [6], 106: [6], 107: [6], 108: [6], 109: [6], 110: [6], 111: [6], 112: [6], 113: [6], 114: [6], 115: [6], 116: [6], 117: [7], 118: [7], 119: [7], 120: [7], 121: [7], 122: [7], 123: [7], 124: [7], 125: [7], 126: [7], 127: [7], 128: [7], 129: [7], 130: [7], 131: [7], 132: [7], 133: [7], 134: [7], 135: [8], 136: [8], 137: [8], 138: [8], 139: [8], 140: [8], 141: [8], 142: [8], 143: [8], 144: [8], 145: [8], 146: [8], 147: [9], 148: [9], 149: [9], 150: [9], 151: [9], 152: [9], 153: [9], 154: [9], 155: [9], 156: [9], 157: [9], 158: [9], 159: [9], 160: [9]}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-566-8de38025c9f0>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-566-8de38025c9f0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for w in q_clean\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "q = input()\n",
    "q_clean = cleanData(q)\n",
    "for w in q_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><table><tr><td>%s</td><td>need</td></tr><tr><td>%s</td><td>beati</td></tr><tr><td>%s</td><td>appart</td></tr></table></body></html>\n"
     ]
    }
   ],
   "source": [
    "output = \"<html><body><table>\"\n",
    "for key in q_clean:\n",
    "  output += \"<tr><td>%s</td><td>{}</td></tr>\".format(key)\n",
    "output += \"</table></body></html>\"\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><th><td><b>Term<b></td></th><tr><td>need</td></tr><tr><td>beati</td></tr><tr><td>appart</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "data = [[1,2,3],\n",
    "         [4,5,6],\n",
    "         [7,8,9],\n",
    "         ]\n",
    "out='<table><th><td><b>Term<b></td></th>'\n",
    "for k in q_clean:\n",
    "    out +='<tr><td>'+str(k)+'</td></tr>'\n",
    "out+='</table>'\n",
    "\n",
    "display(HTML(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with term frequency per fid by using the modified getWordsTSV function below\n",
    "#obsolete now as tf for every word is directly calculated in getTFIDF\n",
    "'''\n",
    "def getTF(fid):\n",
    "    tfd = {}\n",
    "    words = getWordsTSV_dup(fid)\n",
    "    for word in words:\n",
    "        if word in tfd:\n",
    "            tfd[word] =  tfd[word]+1\n",
    "            #replace word with term id from vocabulary\n",
    "        else:\n",
    "            tfd[word] = 1\n",
    "    for tfs in tfd:\n",
    "        tfd[tfs] = tfd[tfs]/len(words)\n",
    "    return tfd\n",
    "'''\n",
    "\n",
    "#modified getWordsTSV function that creates a list with all words in the doc and does not remove the duplicates\n",
    "def getWordsTSV_dup(fid):\n",
    "    fileWords=[]\n",
    "    for i in open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\"):\n",
    "        #words.append(cleanData(i[0][4]))\n",
    "        data = [i.strip('\\n').split('\\t') for i in open('data/doc_'+str(fid)+'.tsv',encoding=\"utf8\")]\n",
    "        for w in (cleanData(data[0][4].replace('\\\\n', ' '))):\n",
    "            fileWords.append(w)\n",
    "    return(fileWords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the inverse data frquency(idf) of a word\n",
    "def getIDF(word):\n",
    "    '''#set counter for occurences of the term in the documents\n",
    "    #that contain the term to 0\n",
    "    #N = 0'''\n",
    "    #get the ids of the documents in which the term occures\n",
    "    files = getDocsWithID(int(getID(word)))\n",
    "    \n",
    "    ''' \n",
    "    #iterate over the list with the document ids\n",
    "    for file in files:\n",
    "        #get the words of each document\n",
    "        words = getWordsTSV_dup(file)\n",
    "        #check how often the term occurs in the documents\n",
    "        for x in words:\n",
    "            if x == word: \n",
    "                N += 1+\n",
    "                '''\n",
    "    #number of docs in which the terms occurs it the length of files\n",
    "    #filecount = total number of files\n",
    "    idf = math.log(fileCount/len(files))\n",
    "    return idf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the tfidf for one word\n",
    "def getTFIDF(word, docID):\n",
    "    \n",
    "    files = getDocsWithID((int(getID(word))))\n",
    "    print(files)\n",
    "    words =[]\n",
    "    N = 0\n",
    "    for file in files:\n",
    "        words.extend(getWordsTSV_dup(file))\n",
    "    for x in words:\n",
    "        #print(x)\n",
    "        if x == word:\n",
    "             N += 1\n",
    "    tf = N/len(words)\n",
    "    tfidf = tf * getIDF(word)\n",
    "    print(word)\n",
    "    print(words)\n",
    "    print(N)\n",
    "    print(tf)\n",
    "    print(tfidf)\n",
    "\n",
    "    \n",
    "    '''       \n",
    "        tfd = {}\n",
    "    words = getWordsTSV_dup(fid)\n",
    "    for word in words:\n",
    "        if word in tfd:\n",
    "            tfd[word] =  tfd[word]+1\n",
    "            #replace word with term id from vocabulary\n",
    "        else:\n",
    "            tfd[word] = 1\n",
    "    for tfs in tfd:\n",
    "        tfd[tfs] = tfd[tfs]/len(words)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8]\n",
      "bed\n",
      "['welcom', 'stay', 'privat', 'room', 'queen', 'bed', 'detach', 'privat', 'bathroom', 'second', 'floor', 'anoth', 'privat', 'bedroom', 'sofa', 'bed', 'avail', 'addit', 'guest', 'addit', 'guest', 'iah', 'airport', 'airport', 'pick', 'drop', 'avail', 'trip', 'beauti', 'bedroom', 'queen', 'size', 'bed', 'closet', 'pet', 'hous', 'alway', 'clean', 'bathroom', 'share', 'suppli', 'towel', 'shampoo', 'avail', 'mile', 'downtown', 'tcu', 'tcc', 'stockyard']\n",
      "3\n",
      "0.061224489795918366\n",
      "0.024824394373969248\n"
     ]
    }
   ],
   "source": [
    "getTFIDF('bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beauti',\n",
       " 'bedroom',\n",
       " 'queen',\n",
       " 'size',\n",
       " 'bed',\n",
       " 'closet',\n",
       " 'pet',\n",
       " 'hous',\n",
       " 'alway',\n",
       " 'clean',\n",
       " 'bathroom',\n",
       " 'share',\n",
       " 'suppli',\n",
       " 'towel',\n",
       " 'shampoo',\n",
       " 'avail',\n",
       " 'mile',\n",
       " 'downtown',\n",
       " 'tcu',\n",
       " 'tcc',\n",
       " 'stockyard']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWordsTSV_dup(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['welcom',\n",
       " 'origin',\n",
       " 'home',\n",
       " 'recent',\n",
       " 'purchas',\n",
       " 'home',\n",
       " 'mile',\n",
       " 'outsid',\n",
       " 'downtown',\n",
       " 'fort',\n",
       " 'worth',\n",
       " 'happi',\n",
       " 'restor',\n",
       " 'origin',\n",
       " 'charact',\n",
       " 'home',\n",
       " 'built',\n",
       " 'minut',\n",
       " 'drive',\n",
       " 'downtown',\n",
       " 'offer',\n",
       " 'across',\n",
       " 'street',\n",
       " 'current',\n",
       " 'rejuven',\n",
       " 'gateway',\n",
       " 'park']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWordsTSV_dup(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
