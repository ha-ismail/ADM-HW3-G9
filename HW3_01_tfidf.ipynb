{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from googletrans import Translator\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "#translator = Translator()\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading tsvs and getting cleaned stemmed dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the given dataset into pandas for processing using only the needed columns\n",
    "data = pd.read_csv('Airbnb_Texas_Rentals.csv', usecols= ['average_rate_per_night', 'bedrooms_count','city', 'date_of_listing', 'description', 'latitude','longitude','title', 'url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a file for every row in data(the given data of airbnb)\n",
    "fileCount = 0\n",
    "for index, r in data.iterrows():\n",
    "    data_temp = data.loc[index:index]\n",
    "    fileCount +=1\n",
    "    data_temp.to_csv('data/doc_'+str(index+1)+'.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the functions\n",
    "\n",
    "\n",
    "    # list of unique words (terms) to be used to build the vocabulary\n",
    "words = []\n",
    "\n",
    "def cleanData(rawData):\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "        # TODO translatoin\n",
    "        #lang = detect(t4[0])\n",
    "        #print(lang)\n",
    "        #rawData = translator.translate(rawData, dest='en')\n",
    "\n",
    "        # get words lowercased\n",
    "        t0 = rawData.lower()\n",
    "        # remove puctuations\n",
    "        t1 = tokenizer.tokenize(t0)\n",
    "        #t2Data = stemmer.stem(i for i in t1Data)\n",
    "        #print(len(t1))\n",
    "        # reomve stop words\n",
    "        t2 =[]\n",
    "        t2 = [t1[i] for i in range(0,len(t1)) if t1[i] not in stop_words]\n",
    "\n",
    "        # stemm words\n",
    "        t3 = [stemmer.stem(t2[i]) for i in range(0, len(t2))]\n",
    "\n",
    "        # remove nummbers and strings starting with numbers\n",
    "        t4 = [t3[i] for i in range(0, len(t3)) if t3[i][0].isdigit()==False]\n",
    "\n",
    "\n",
    "        #print(t4)\n",
    "        return(t4)\n",
    "\n",
    "def getWordsTSV(fid):\n",
    "        fileWords=[]\n",
    "        for i in open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\"):\n",
    "            #words.append(cleanData(i[0][4]))\n",
    "            data = [i.strip('\\n').split('\\t') for i in open('data/doc_'+str(fid)+'.tsv',encoding=\"utf8\")]\n",
    "            for w in (cleanData(data[0][4].replace('\\\\n', ' '))):\n",
    "                if w not in fileWords: fileWords.append(w)\n",
    "        return(fileWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1,fileCount):\n",
    "    t = getWordsTSV(i)\n",
    "    for w in t:\n",
    "        if w not in words:\n",
    "            words.append(w)\n",
    "#print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PS\n",
    "dunno why the stemmer is removing the last 'e' from any word\n",
    "we need to look at the stem function again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the vocabulary file from the words \n",
    "wordsCount=0\n",
    "with open('vocabulary.csv','wb') as vfile:\n",
    "    for i in range(0,len(words)):\n",
    "        vfile.write(str(wordsCount).encode())\n",
    "        vfile.write(str('\\t').encode())\n",
    "        vfile.write(str(words[i]).encode())\n",
    "        vfile.write('\\n'.encode())\n",
    "        wordsCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9617\n"
     ]
    }
   ],
   "source": [
    "print(wordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "'''# creating index-file by loading vocabulary file and then comparing files with all vocabularys\n",
    "with open('vocabulary.csv', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    voc = list(map(tuple, reader))\n",
    "#print(voc)\n",
    "\n",
    "index = {}\n",
    "for i in range(len(voc)):\n",
    "    tempL=[]\n",
    "\n",
    "    for j in range(1,fileCount+1):\n",
    "        temp = getWordsTSV(j)\n",
    "        print(i)\n",
    "        if voc[i][1] in temp:\n",
    "            tempL.append(j)\n",
    "            \n",
    "        if len(tempL)!=0: index[i]= tempL\n",
    "        \n",
    "            \n",
    "#print(index)  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating index-file by loading vocabulary file and then comparing files with all vocabularys\n",
    "with open('vocabulary.csv', newline='') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    voc = np.array(list(map(tuple, reader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 'welcom']\n",
      " ['1' 'stay']\n",
      " ['2' 'privat']\n",
      " ['3' 'room']\n",
      " ['4' 'queen']\n",
      " ['5' 'bed']\n",
      " ['6' 'detach']\n",
      " ['7' 'bathroom']\n",
      " ['8' 'second']\n",
      " ['9' 'floor']]\n"
     ]
    }
   ],
   "source": [
    "print(voc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocWords=voc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9617\n"
     ]
    }
   ],
   "source": [
    "print(len(vocWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get ID of a given term (this one uses the voc array instead of reading from file)\n",
    "def getIDfromVoc(term):\n",
    "    for t in range(len(voc)):\n",
    "        if voc[t,1] == term:\n",
    "            return(t)\n",
    "    return(-1)\n",
    "# function to get Term for a given term ID\n",
    "def getTermfromVoc(tid):\n",
    "    for t in range(len(voc)):\n",
    "        if voc[t,0] == tid:\n",
    "            return(voc[t,1])\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welcom'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[0,1]\n",
    "#print(getTermfromVoc(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "getIDfromVoc('welcom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the index\n",
    "index = {}\n",
    "for f in range(1,fileCount+1):\n",
    "    temp = getWordsTSV(f)\n",
    "    for t in temp:\n",
    "        termID=getIDfromVoc(t)\n",
    "        if termID in index:\n",
    "            index[termID].append(f)\n",
    "        else:\n",
    "            index[termID]=[f]\n",
    "                \n",
    "\n",
    "            \n",
    "#print(index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "print(index[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have done another fucntion with same functionality: find above!\n",
    "def getID(term):\n",
    "    with open('vocabulary.csv', newline='') as voc:\n",
    "        line = csv.reader(voc, delimiter='\\t')\n",
    "        w = list(map(tuple, line))\n",
    "        #print(w[0][1])\n",
    "        for i in w:\n",
    "            if term == i[1]:\n",
    "                return (i[0])\n",
    "        else:\n",
    "            return None \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED FOR THIS FUNCTION function takes term ID and returns (from index) the list of files containing the term\n",
    "def getDocsWithID(tid):\n",
    "    for k in index:\n",
    "        if tid == k:\n",
    "            return(index.get(k))\n",
    "    return None\n",
    "\n",
    "#getting error: TypeError: 'int' object is not iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed it to check if the doc contains all terms\n",
    "def getDocswithQuery(q):\n",
    "    ts = cleanData(q)\n",
    "    #docsIDs = getDocsWithID(int(getID(ts[0])))\n",
    "    docsIDs = index[getIDfromVoc(ts[0])]\n",
    "    if docsIDs == None : return None\n",
    "    if len(ts)>1:\n",
    "        #docsIDs = getDocsWithID(int(getID(ts[0])))\n",
    "        for t in ts[1:]:\n",
    "            tid = getIDfromVoc(t)\n",
    "            if tid != -1:\n",
    "                tempDocs = index.get(tid)\n",
    "                if tempDocs != None:\n",
    "                    docsIDs = set(docsIDs).intersection(tempDocs)\n",
    "            else: return None\n",
    "    return(list(docsIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated, find below!\n",
    "def old_getDetails(fid):\n",
    "    with open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\") as file:\n",
    "        line = csv.reader(file, delimiter='\\t')\n",
    "        cls = list(map(str, *line))\n",
    "        print(cls[7],cls[4], cls[2], cls[8])\n",
    "        # TODO create a table and list the details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton retuns the details of a file given file id\n",
    "\n",
    "def getDetails(fid):\n",
    "    detlist =[]\n",
    "    with open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\") as file:\n",
    "        line = csv.reader(file, delimiter='\\t')\n",
    "        cls = list(map(str, *line))\n",
    "        detlist= [cls[7],cls[4].rstrip('\\r\\n').replace('\\\\n', ' '), cls[2], cls[8]]\n",
    "        #TODO create a table and list the details\n",
    "        return detlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "def cleanhtml(raw_html):\n",
    "    soup = BeautifulSoup(raw_html)\n",
    "    for span_tag in soup.findAll('span'):\n",
    "        span_tag.replace_with('')\n",
    "    return(html.unescape(str(soup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I defined two functions for the visualizing stuff\n",
    "def hoohleResult(r):\n",
    "    rhtm ='<div class=\"h_result\"><div class=\"h_title\"><a href=\"'+r[3]+'\">'+r[0]+'</a></div>'\n",
    "    rhtm +='<div class=\"h_link\"><a href=\"'+r[3]+'\">'+r[3]+'</a></div>'\n",
    "    rhtm +='<div class=\"h_disc\">'+r[1].replace('\\n', '')[:300]+'... </div>'\n",
    "    rhtm +='</div>'\n",
    "    return (rhtm)\n",
    "    \n",
    "def hoohleResults(query):\n",
    "    docs = getDocswithQuery(query)\n",
    "    styles = open(\"style/style.css\", \"r\").read()\n",
    "    hhtm = '<style>%s</style>' % styles     \n",
    "    hhtm +='<div class=\"Hoohle\" ><div class=\"h_results\">'\n",
    "    if docs != None:\n",
    "        for doc in docs:\n",
    "            hhtm +=hoohleResult(getDetails(doc))\n",
    "    else:\n",
    "        hhtm +='Sorry! No results found for your request!'\n",
    "    hhtm += '</div></div>'\n",
    "    display(HTML(hhtm))\n",
    "\n",
    "\n",
    "def printResults(query):\n",
    "    docs = getDocswithQuery(query)\n",
    "    #det =[['Title','Description', 'City','Url']]\n",
    "    #for doc in docs:\n",
    "    #    det.append(getDetails(doc))\n",
    "    #columns = ('Title','Description', 'City','Url')\n",
    "    #n_rows = len(det)\n",
    "    html='<table align=\"left\"><tr><th>Title</th><th>Description</th><th>City</th><th>URL</th></tr>'\n",
    "    if docs != None:\n",
    "\n",
    "        for doc in docs:\n",
    "            l = getDetails(doc)\n",
    "            html+='<tr><td>'+l[0]+'</td><td>'+l[1]+'</td><td>'+l[2]+'</td><td>'+l[3]+'</td></tr>'\n",
    "    else:\n",
    "        html+='<tr><td>Sorry! Nothing found!</td></tr>'\n",
    "    html+='</table>'\n",
    "    display(HTML(html))\n",
    "    #table = ff.create_table(det, height_constant=60)\n",
    "    \n",
    "    #plotly.offline.iplot(table, filename='simple_table')\n",
    "    #plt.show()\n",
    "    #return det[0][1]\n",
    "    \n",
    "    '''\n",
    "    maybe remove the stuff we commented out if we don't need it anymore?\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {\n",
       "    width:100%;\n",
       "    border:1px solid #eee;\n",
       "    margin: 3px;\n",
       "    padding:3px;\n",
       "    font-family: Tahoma;\n",
       "    background-color: #91ced4;\n",
       "    text-align: left;\n",
       "    float: left;\n",
       "    position: relative;\n",
       "    left: 0;\n",
       "    \n",
       "}\n",
       "table, tr, td, th{\n",
       "    text-align:left;\n",
       "}\n",
       "\n",
       ".container .div_result{\n",
       "    width:90%;\n",
       "    float: left;\n",
       "    position: relative;\n",
       "    left: 5%;\n",
       "    top: 10px;\n",
       "    \n",
       "    \n",
       "}\n",
       "\n",
       ".container table td, table th {\n",
       "  color: #2b686e;\n",
       "  padding: 10px;\n",
       "}\n",
       ".container table td {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       ".container table td:last-child {\n",
       "  font-size: 0.95em;\n",
       "  line-height: 1.4;\n",
       "  text-align: left;\n",
       "}\n",
       ".container table th {\n",
       "  background-color: #daeff1;\n",
       "  font-weight: 300;\n",
       "}\n",
       ".container table tr:nth-child(2n) {\n",
       "  background-color: white;\n",
       "}\n",
       ".container table tr:nth-child(2n+1) {\n",
       "  background-color: #edf7f8;\n",
       "}\n",
       ".container table tr:hover {\n",
       "  background-color: #efe1ac;\n",
       "  border: 1px solid #f4ce42;\n",
       "\n",
       "}\n",
       ".Hoohle{\n",
       "    font-family:arial,sans-serif;\n",
       "    width:100%;\n",
       "    border:1px solid #eee;\n",
       "    margin: 3px;\n",
       "    padding:3px;\n",
       "    background-color: #fff;\n",
       "    text-align: left;\n",
       "    float: left;\n",
       "    position: relative;\n",
       "    left: 0;\n",
       "}\n",
       ".Hoohle h_results{\n",
       "    margin:3px;\n",
       "}\n",
       ".Hoohle div.h_result{\n",
       "    padding-left:3px;\n",
       "    margin-bottom:10px;\n",
       "    width: 600px;\n",
       "}\n",
       ".Hoohle div.h_result:hover{\n",
       "    /*background-color: #eee;*/\n",
       "    border-left:2px solid #acc6ef;\n",
       "    \n",
       "}\n",
       ".Hoohle div{\n",
       "    font-family:arial,sans-serif;\n",
       "}\n",
       ".Hoohle div.h_title a:link, a:visited{\n",
       "    color: rgb(26, 13, 171);\n",
       "    display: inline-block;\n",
       "    font-size: 18px;\n",
       "    font-family:arial,sans-serif;\n",
       "}\n",
       ".Hoohle div.h_link a:link, a:visited{\n",
       "    color: #006621;\n",
       "    display: inline-block;\n",
       "    font-size: 14px;\n",
       "    font-family:arial,sans-serif;\n",
       "    padding-top:1px;\n",
       "}\n",
       ".Hoohle div.h_link a:hover{\n",
       "    text-decoration: none;\n",
       "}\n",
       ".Hoohle h_disc{\n",
       "    font-size: small;\n",
       "    \n",
       "}\n",
       ".h_disc > span:nth-child(odd)[style],\n",
       ".h_disc > span:nth-child(even)[style]{\n",
       "    font-style: normal; !important;\n",
       "}\n",
       "\n",
       "/* unvisited link */\n",
       ".container a:link {\n",
       "    color: red;\n",
       "}\n",
       "\n",
       "/* visited link */\n",
       ".container a:visited {\n",
       "    color: green;\n",
       "}\n",
       "\n",
       "/* mouse over link */\n",
       ".container a:hover {\n",
       "    color: hotpink;\n",
       "    text-decoration: underline;\n",
       "}\n",
       "\n",
       "/* selected link */\n",
       ".container a:active {\n",
       "    color: blue;\n",
       "    text-decoration: underline;\n",
       "}\n",
       "\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height: none;\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "\n",
       ".package_header {\n",
       "    width: 100%;\n",
       "    background-color: #0e2b59;\n",
       "    color: #ffffff;\n",
       "    font-size: 14px;\n",
       "    text-align: center;\n",
       "    padding-top: 8px;\n",
       "    padding-right: 8px;\n",
       "    padding-bottom: 8px;\n",
       "    padding-left: 8px;\n",
       "}\n",
       "\n",
       ".placeholder {\n",
       "    width: 100%;\n",
       "    background-color: #ffffff;\n",
       "    height: 6px;\n",
       "}\n",
       "\n",
       ".passed_test_table {\n",
       "  display: table;         \n",
       "  width: 100%;         \n",
       "\n",
       "  background-color: #ebffd3;                \n",
       "  border-spacing: 5px;\n",
       "}\n",
       "\n",
       "# (...) rest of css classes omitted </style><div class=\"Hoohle\" ><div class=\"h_results\"><div class=\"h_result\"><div class=\"h_title\"><a href=\"https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX\">2 Private rooms/bathroom 10min from IAH airport</a></div><div class=\"h_link\"><a href=\"https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX\">https://www.airbnb.com/rooms/18520444?location=Cleveland%2C%20TX</a></div><div class=\"h_disc\">Welcome to stay in private room with queen bed and detached private bathroom on the second floor. Another private bedroom with sofa bed is available for additional guests. 10$ for an additional guest. 10min from IAH airport Airport pick-up/drop off is available for $10/trip.... </div></div><div class=\"h_result\"><div class=\"h_title\"><a href=\"https://www.airbnb.com/rooms/513509?location=Canyon%20Lake%2C%20TX\">The River Song Cottage in Wimberley</a></div><div class=\"h_link\"><a href=\"https://www.airbnb.com/rooms/513509?location=Canyon%20Lake%2C%20TX\">https://www.airbnb.com/rooms/513509?location=Canyon%20Lake%2C%20TX</a></div><div class=\"h_disc\">Charming 1 bedroom cottage in Wimberley, Texas. Conveniently located less than one mile from the square, Blue Hole Regional Park and one of the last outdoor theaters in the nation, The Corral. Wimberley is one of the best kept secrets of the southwest. We're an easy 45 minute commute to Austin, but ... </div></div><div class=\"h_result\"><div class=\"h_title\"><a href=\"https://www.airbnb.com/rooms/5769?location=Cedar%20Park%2C%20TX\">NW Austin Room</a></div><div class=\"h_link\"><a href=\"https://www.airbnb.com/rooms/5769?location=Cedar%20Park%2C%20TX\">https://www.airbnb.com/rooms/5769?location=Cedar%20Park%2C%20TX</a></div><div class=\"h_disc\">Looking for a comfortable inexpensive room to stay for a night? A week or more? Join us in our northwest Austin home where the house is tidy, nicely decorated and we are friendly, responsible, courteous hosts. Single or couples welcome. We have two small, fairly quiet dogs and welcome travelers from... </div></div><div class=\"h_result\"><div class=\"h_title\"><a href=\"https://www.airbnb.com/rooms/16311303?location=Canyon%20Lake%2C%20TX\">Texas Lake Haus- Lake Views, One Acre, Sleeps 8!</a></div><div class=\"h_link\"><a href=\"https://www.airbnb.com/rooms/16311303?location=Canyon%20Lake%2C%20TX\">https://www.airbnb.com/rooms/16311303?location=Canyon%20Lake%2C%20TX</a></div><div class=\"h_disc\">TEXAS LAKE HAUS - a SkyRun Texas Property    Welcome to the Texas Lake Haus, your one acre piece of paradise nestled in the hills overlooking the clear blue waters of Canyon Lake!   Texas Lake Haus might just become your family's Hill Country vacation tradition. This spacious home near 2000 square f... </div></div><div class=\"h_result\"><div class=\"h_title\"><a href=\"https://www.airbnb.com/rooms/7660270?location=Cisco%2C%20TX\">Lazy TK Ranch, Bunkhouse Buckaroo</a></div><div class=\"h_link\"><a href=\"https://www.airbnb.com/rooms/7660270?location=Cisco%2C%20TX\">https://www.airbnb.com/rooms/7660270?location=Cisco%2C%20TX</a></div><div class=\"h_disc\">Located in the Bunkhouse, the Buckaroo room has a comfy cowboy feel. Featuring a Queen bed this room sleeps 2 people but has enough room to add an additional twin if needed to sleep 3.   Dish TV, free WiFi and private bath.   Guests have access to the main living area and kitchen in the Bunkhouse. G... </div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hoohleResults(\"Welcome to stay i room with queen bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9000, 1, 430]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDocswithQuery(\"Welcome to stay in private room with queen bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9617\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2110"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with term frequency per fid by using the modified getWordsTSV function below\n",
    "\n",
    "def getTF(fid, term):\n",
    "    tfd = {}\n",
    "    words = getAllWordsTSV(fid)\n",
    "    n = 0\n",
    "    for w in words:\n",
    "        if w == term:\n",
    "            n+1\n",
    "    return (n/len(words))\n",
    "\n",
    "def getIDF(word):\n",
    "    return (math.log(fileCount/len(index(getIDfromDov(word)))))\n",
    "\n",
    "\n",
    "    #get the ids of the documents in which the term occures\n",
    "    files = getDocsWithID(int(getID(word)))\n",
    "\n",
    "    #number of docs in which the terms occurs it the length of files\n",
    "    #filecount = total number of files\n",
    "    idf = math.log(fileCount/len(files))\n",
    "    return idf\n",
    "\n",
    "    if term in words:\n",
    "        for word in words:\n",
    "            if word == term:\n",
    "                if word in tfd:\n",
    "                    tfd[term] =  tfd[term]+1\n",
    "                    #maybe replace word with term id from vocabulary\n",
    "                else:\n",
    "                    tfd[term] = 1\n",
    "    else: return None\n",
    "    for tfs in tfd:\n",
    "        tfd[tfs] = tfd[tfs]/len(words)\n",
    "    return tfd\n",
    "\n",
    "\n",
    "#modified getWordsTSV function that creates a list with all words in the doc and does not remove the duplicates\n",
    "def getWordsTSV_dup(fid):\n",
    "    fileWords=[]\n",
    "    for i in open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\"):\n",
    "        #words.append(cleanData(i[0][4]))\n",
    "        data = [i.strip('\\n').split('\\t') for i in open('data/doc_'+str(fid)+'.tsv',encoding=\"utf8\")]\n",
    "        for w in (cleanData(data[0][4].replace('\\\\n', ' '))):\n",
    "            fileWords.append(w)\n",
    "    return(fileWords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the inverse data frquency(idf) of a word\n",
    "def getIDF(word):\n",
    "    \n",
    "    #get the ids of the documents in which the term occures\n",
    "    files = getDocsWithID(int(getID(word)))\n",
    "\n",
    "    #number of docs in which the terms occurs it the length of files\n",
    "    #filecount = total number of files\n",
    "    idf = math.log(fileCount/len(files))\n",
    "    return idf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the tfidf for one word\n",
    "\n",
    "# return all clean terms in a given file (including duplicates)\n",
    "def getAllWordsTSV(fid):\n",
    "    fileWords=[]\n",
    "    for i in open('data/doc_'+str(fid)+'.tsv', encoding=\"utf8\"):\n",
    "        data = [i.strip('\\n').split('\\t') for i in open('data/doc_'+str(fid)+'.tsv',encoding=\"utf8\")]\n",
    "        for w in (cleanData(data[0][4].replace('\\\\n', ' '))):\n",
    "            fileWords.append(w)\n",
    "    return(fileWords)\n",
    "\n",
    "# for a given (file id, term), returns the term frequency in this file\n",
    "def get_TF(fid, term):\n",
    "    words = getAllWordsTSV(fid)\n",
    "    n = 0\n",
    "    for w in words:\n",
    "        if w == term:n+=1\n",
    "    return (n/len(words))\n",
    "\n",
    "# returns the IDF for a given term in the whole data we have\n",
    "def get_IDF(word):\n",
    "    return (math.log(fileCount/len(index[getIDfromVoc(word)])))\n",
    "# returns the TFIDF for a given (file id, term)\n",
    "def get_TFIDF(fid, termID):\n",
    "    #getting TF for term in document with document id = fid and multiply it with the IDF of the term\n",
    "    term = voc[termID][1]\n",
    "    return ([fid, get_TF(fid, term) * get_IDF(term)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1039563534909512"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDF(1,'bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0.07707036291666503]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_TFIDF(1,1)\n",
    "#voc[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getAllWordsTSV(1)\n",
    "#len(index[getIDfromVoc('bed')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexTFIDF = {}\n",
    "for termID in index:\n",
    "    indexTFIDF[termID]=[]\n",
    "    for docID in index[termID]:\n",
    "        indexTFIDF[termID].append(get_TFIDF(docID, termID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getIDfromVoc(getTermfromVoc(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(getTermfromVoc(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.07707036291666503],\n",
       " [14, 0.05018535259689816],\n",
       " [23, 0.08631880646666483],\n",
       " [27, 0.11357737692982213],\n",
       " [30, 0.16599770474358622],\n",
       " [31, 0.041499426185896554],\n",
       " [40, 0.08299885237179311],\n",
       " [47, 0.05018535259689816],\n",
       " [56, 0.04071641814465322],\n",
       " [58, 0.03923582112121128]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexTFIDF[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineSimi(v1,v2):\n",
    "    return (1 - spatial.distance.cosine(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF_query(q):\n",
    "    terms = cleanData(q)\n",
    "    v = []\n",
    "    uniqTerms=[]\n",
    "    for t in terms:\n",
    "        if t not in uniqTerms:\n",
    "            uniqTerms.append(t)\n",
    "            v.append(terms.count(t))\n",
    "    return([x/len(terms) for x in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4, 0.2, 0.2, 0.2]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDF_query('hello hello fucking bad ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
